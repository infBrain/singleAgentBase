## 任务 1：前端体验变差（frontend 的 P99 延迟升高）

### A. 数据层（Data Layer）

**Simple**

1. 查询 `frontend-1` 在最近 10 分钟的 `rrt` 的 `P99` 值（或 p50/p95/p99 三个一起给）。
2. 查询最近 10 分钟内 `frontend-0/frontend-1/frontend-2` 的 `error_ratio` 分别是多少。
3. 查询最近 10 分钟 `timeout` 是否显著升高（给出 `frontend` 相关请求的 timeout 计数/比例）。

**Hard**

4. 查询最近 30 分钟内 `rrt` 变化率最大的 `pod` Top-5（不限定服务，直接按 pod 维度跑）。
5. 查询最近 15 分钟内 `server_error_ratio > 1%` 的所有 pod 列表，并按 `server_error_ratio` 降序排序。
6. 查询最近 30 分钟内满足 “连续 5 个采样点 `rrt` 超过阈值 θ” 的 pod（输出 pod + 持续区间）。

------

### B. 知识层（Knowledge / Topology Layer）

**Simple**

7. 查询 `frontend` 的直接下游依赖服务有哪些（根据你提供的调用关系）。

**Hard**

8. 查询从 `frontend` 出发的**完整下游链路**（展开到叶子）：包含 `checkoutservice -> paymentservice -> shippingservice -> emailservice` 这条链。
9. 查询 `emailservice` 的所有上游服务集合（按 hop 分层输出：1-hop/2-hop/3-hop…）。
10. 查询 `aiops-k8s-03` 节点上部署了哪些服务（按 service 聚合输出，而不是按 pod）。

- 你给的调度信息里，aiops-k8s-03 上至少包含：`adservice-1/cartservice-0/checkoutservice-1/currencyservice-1/emailservice?（无）/frontend-1/paymentservice-0/productcatalogservice-1/recommendationservice-1/shippingservice-0`（以你的表为准）。

------

### C. 数据 + 知识层（Data + Knowledge）

**Simple**

11. 查询最近 10 分钟内 `frontend` 的所有下游服务（adservice、productcatalogservice、currencyservice、recommendationservice、cartservice、checkoutservice）各自的 `rrt P99`，输出一个按 P99 降序的列表。

**Hard**

12. 查询最近 10 分钟内：导致 `frontend` 端到端 `rrt` 升高的**贡献最大下游服务**是谁（输出 service + contribution score + 证据：它的 rrt/timeout/error_ratio）。
13. 查询最近 10 分钟内：`frontend -> checkoutservice -> paymentservice -> shippingservice -> emailservice` 这条链路中，**瓶颈主要位于哪一层**（checkout/payment/shipping/email 中哪一层 rrt/timeout 最异常），并给出每层的 P99 对比。
14. 查询最近 10 分钟内：如果 `frontend` 的 `error_ratio` 上升，同时要求找出“**下游都健康（error_ratio/timeout 正常）但 frontend 仍慢**”的情况，输出可能指向的根因方向（如 frontend 自身、节点资源、网络等），并列出对应证据指标（node_cpu_usage_rate / node_network_* / pod_cpu_usage 等）。

------

## 任务 2：结算链路故障（checkoutservice 错误率升高，怀疑 payment 链路）

### A. 数据层（Data Layer）

**Simple**

1. 查询最近 20 分钟 `checkoutservice` 的 `error_ratio`（或 `server_error_ratio`）曲线。
2. 查询最近 20 分钟 `paymentservice` 的 `timeout` 与 `server_error_ratio`。
3. 查询最近 20 分钟 `shippingservice` 的 `rrt P99`。

**Hard**

4. 查询最近 20 分钟：`error_ratio > 2%` 的所有 pod（全系统范围），并标注它们的错误率。
5. 查询最近 20 分钟：`request` 增长最快的 pod Top-5（可能反映流量突增）。
6. 对比两个窗口（例如 `[T-40m, T-20m]` vs `[T-20m, T]`）：`checkoutservice` 的 `error_ratio` 环比变化（输出 before/after/diff/%）。

------

### B. 知识层（Knowledge / Topology Layer）

**Simple**

7. 查询 `checkoutservice` 的直接下游服务是谁（根据给定关系应为 `paymentservice`）。

**Hard**

8. 查询以 `checkoutservice` 为起点的完整下游链路（直到 emailservice）。
9. 查询 `paymentservice` 的所有上游服务（应包含 checkoutservice，以及再往上可追到 frontend）。
10. 查询 `paymentservice` 三个 pod 的部署节点分别是哪几个：

- `paymentservice-0 -> aiops-k8s-03`
- `paymentservice-1 -> aiops-k8s-08`
- `paymentservice-2 -> aiops-k8s-01`

------

### C. 数据 + 知识层（Data + Knowledge）

**Simple**

11. 查询最近 20 分钟 `paymentservice` 三个 pod 的 `timeout` 分别是多少，并按 timeout 降序输出（pod 级别）。

**Hard**

12. 当 `checkoutservice` 错误率升高时，沿着 `checkoutservice -> paymentservice -> shippingservice -> emailservice` 这条链，找出**最可能的根因服务**（输出 Top-3 service + 证据：其 error_ratio/timeout/rrt 的异常程度与时间对齐）。
13. 查询最近 20 分钟：`paymentservice` 哪个 pod 异常最明显，并进一步输出该 pod 所在节点（aiops-k8s-03/08/01）在同一时间窗的 `node_cpu_usage_rate / node_memory_usage_rate / node_sockstat_TCP_inuse` 是否同步异常（用来区分“服务自身问题” vs “节点问题”）。
14. 影响面分析：若 `paymentservice` 异常，列出可能受影响的上游服务集合（至少 checkoutservice、frontend），并给出这些上游的 `error_ratio/rrt` 是否出现同步恶化（输出 affected_services + 指标对齐结果）。

------

## 任务 3：节点级资源竞争（同一节点上多服务同时变慢/抖动）

你这个集群里 **aiops-k8s-03** 是典型“高密度节点”（frontend-1、paymentservice-0、shippingservice-0、checkoutservice-1、recommendationservice-1、currencyservice-1、productcatalogservice-1、adservice-1、cartservice-0 等都在上面），非常适合做“资源竞争”类 Hard 题。

### A. 数据层（Data Layer）

**Simple**

1. 查询 `aiops-k8s-03` 最近 30 分钟的 `node_cpu_usage_rate`、`node_memory_usage_rate`。
2. 查询 `aiops-k8s-03` 最近 30 分钟的 `node_network_receive_packets_total`、`node_network_transmit_packets_total`。

**Hard**

3. 查询最近 30 分钟：所有节点里 `node_cpu_usage_rate` 峰值最高的 Top-3 节点。
4. 查询最近 30 分钟：所有节点里 `node_sockstat_TCP_inuse` 增长最快的 Top-3 节点（反映连接数压力）。
5. 查询最近 30 分钟：在 pod 维度里 `pod_network_transmit_bytes` 增长最快的 Top-5 pod。

------

### B. 知识层（Knowledge / Topology Layer）

**Simple**

6. 查询 `aiops-k8s-03` 节点上有哪些 pod（直接从你给的调度表取）。

**Hard**

7. 将 `aiops-k8s-03` 上的 pod 按 service 聚合，输出 `{service: [pods...]}` 的映射。
8. 查询 `aiops-k8s-03` 上这些服务中，哪些是 `frontend` 的直接下游依赖（交集问题：部署关系 ∩ 调用关系）。

------

### C. 数据 + 知识层（Data + Knowledge）

**Simple**

9. 查询最近 30 分钟：`aiops-k8s-03` 上所有 pod 的 `pod_cpu_usage` Top-5（输出 pod + cpu）。

**Hard**

10. 在 `aiops-k8s-03` 上，找出最近 30 分钟**资源竞争最严重的服务组合**：

- 规则例：同节点上两个服务的 `pod_cpu_usage` 同步上升且其 `rrt` 同步恶化（输出 service_pair + contention_score + 证据指标）。

1. 当 `aiops-k8s-03` 的 `node_cpu_usage_rate` 上升时，找出该节点上 **rrt 恶化最明显的服务** Top-3（需要 service↔pods 映射 + rrt 聚合）。
2. “节点问题 vs 单服务问题”判别题：

- 若 `aiops-k8s-03` 节点资源异常，同时该节点上多个服务的 `rrt/error_ratio` 同步变差，则输出“更像节点级问题”的结论；
- 若只有 `paymentservice-0` 的 rrt/timeout 异常、同节点其他服务正常，则输出“更像服务级问题”。
- 该题要求输出：判别结果 + 支撑证据（至少 3 个指标）。

------

## 任务 4（可选但很“有数据味”）：异常重启与稳定性（k8s metadata + 指标联合）

你给的 k8s 表里 `adservice-1` 重启 12 次、`adservice-0` 重启 8 次、`adservice-2` 重启 5 次，这类“重启风暴”非常适合作为一组题。

### A. 数据层（Data Layer）

**Simple**

1. 查询所有 pod 的 `RESTARTS` Top-5（直接用 k8s 元数据）。

**Hard**

2. 对 `adservice-1`：对齐其最近一次重启前后 10 分钟的 `pod_cpu_usage/pod_processes/pod_network_*` 变化，输出最显著变化的指标 Top-3。

### B. 知识层（Knowledge / Topology Layer）

**Simple**

3. `adservice-1` 部署在哪个节点（aiops-k8s-03）。

**Hard**

4. 列出与 `adservice-1` 同节点（aiops-k8s-03）上的其他服务集合（可能用于排查资源争用）。

### C. 数据 + 知识层（Data + Knowledge）

**Hard**

5. 如果 `adservice` 不稳定（重启多），推断对 `frontend` 影响面：

- 先给出调用关系上受影响链路（frontend->adservice）；
- 再对齐 `frontend` 在同一时窗的 `error_ratio/rrt` 是否出现同步恶化（输出 evidence）。